# NYC Taxi Demand Forecasting

Predict hourly yellow taxi demand across Manhattan zones using NYC trip data, weather conditions, and time-based features. This project integrates data engineering, machine learning, and dashboarding to simulate a real-world demand forecasting system with batch inference and monitoring capabilities.

---

## ğŸš€ Project Objective

Forecast the number of yellow taxi rides in Manhattan (New York City) for the next 60 minutes using historical trip records, borough zone data, and NYC weather. This prediction system will:

- Anticipate hourly demand per pickup zone (e.g., Zone 113: Lower Manhattan)
- Enable operational optimization for taxi dispatch systems
- Simulate a batch production-ready ML deployment with real-time extensions

---

## ğŸ—ƒï¸ Data Sources

| Source Type  | Description                                                                                     |
|--------------|-------------------------------------------------------------------------------------------------|
| [TLC Trip Records](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) | Yellow taxi trips from Jan to Mar 2019 (Parquet format)                           |
| Taxi Zone Lookup Table   | CSV mapping `PULocationID` to NYC boroughs and zones (e.g., Upper East Side)        |
| NYC Weather Data         | Hourly temperature, precipitation, humidity, and wind speed for time-series modeling|

---

## ğŸ§  Machine Learning Workflow

The project follows the classical ML pipeline structure: ingest â†’ feature engineering â†’ modeling â†’ batch scoring â†’ dashboarding.

### ğŸ”¹ Step 1: Data Ingestion & Preparation

- Implemented in `data_ingestor.py` and `make_dataset.py`
- Uses Dask for large-scale data loading and cleaning
- Filters out invalid or non-Manhattan records using Taxi Zone Lookup
- Cleans and prepares time-aligned trip records

### ğŸ”¹ Step 2: Feature Engineering

- Implemented in `feature_engineering.py`
- Feature types:
  - **Temporal**: Hour of day, day of week, is_weekend, is_holiday
  - **Lagged Rides**: Ride counts at t-1, t-2, ..., t-24 hours
  - **Weather**: Temperature, wind, precipitation
  - **Zone Metadata**: Categorical labels for borough/zones (from Lookup table)

### ğŸ”¹ Step 3: Baseline Model

- Implemented in `train_baseline_model.py`
- Simple persistence model: predicts next-hour ride count = last-hour ride count
- Serves as a benchmark for more advanced models

### ğŸ”¹ Step 4: Advanced ML Models

- Implemented in `train_advanced_models.py` using LightGBM and XGBoost
- Strategies:
  - Feature expansion: interaction terms, extended lags, richer weather features
  - Algorithm experimentation: LightGBM, XGBoost, Neural Networks
  - Hyperparameter tuning: tree depth, learning rate, boosting rounds
- Uses MLflow for tracking experiments and metrics

### ğŸ”¹ Step 5: Batch Inference System

- Located in `models/batch-scoring_system/`
- Modular 3-stage pipeline:
  1. `00_data_ingestor.py`: loads latest raw data
  2. `01_feature_pipeline.py`: builds features from new data
  3. `02_training_pipeline.py` + `03_inference_pipeline.py`: trains model & forecasts
- Generates predictions for `2019-04-01 00:00:00` (simulating next-hour inference)

### ğŸ”¹ Step 6: Monitoring Dashboard

- Streamlit dashboard implemented in `dashboard.py`
- Features:
  - MAE trends over time
  - Actual vs. Predicted demand visualizations
  - Manhattan heatmap of ride volume
  - Drift analysis and zone-level prediction errors

---

## ğŸ§¾ Folder Structure

```
nyc-taxi-demand-forecasting/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/       # Weather and zone lookup
â”‚   â”œâ”€â”€ raw/            # Raw trip data (Parquet)
â”‚   â”œâ”€â”€ interim/        # Cleaned but unaggregated
â”‚   â””â”€â”€ processed/      # Aggregated time-series data
â”œâ”€â”€ docs/               # Project documentation (Sphinx)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ batch-scoring_system/
â”‚   â”‚   â”œâ”€â”€ 00_data_ingestor.py
â”‚   â”‚   â”œâ”€â”€ 01_feature_pipeline.py
â”‚   â”‚   â”œâ”€â”€ 02_training_pipeline.py
â”‚   â”‚   â”œâ”€â”€ 03_inference_pipeline.py
â”‚   â”‚   â”œâ”€â”€ feature_store/
â”‚   â”‚   â”œâ”€â”€ models_and_metadata/
â”‚   â”‚   â””â”€â”€ predictions/
â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”œâ”€â”€ predict_model.py
â”‚   â””â”€â”€ train_baseline_model.py
â”œâ”€â”€ notebooks/          # Exploratory notebooks
â”œâ”€â”€ references/
â”‚   â”œâ”€â”€ data_dictionary_trip_records_yellow.pdf
â”‚   â””â”€â”€ TLC_Taxi_Zones_Manhattan.jpg
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ problem_statement.md
â”‚   â”œâ”€â”€ lookup_table.md
â”‚   â”œâ”€â”€ large_dataset_assessment.md
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_ingestor.py
â”‚   â”‚   â””â”€â”€ make_dataset.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_advanced_models.py
â”‚   â”‚   â””â”€â”€ predict_model.py
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ analyze_model.py
â”‚       â””â”€â”€ analyze_busy_zones.py
â”œâ”€â”€ environment.yml     # Conda environment specification
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

1. **Clone the repository**
```bash
git clone https://github.com/SebastianGarrido2790/nyc-taxi-demand-forecasting.git
cd nyc-taxi-demand-forecasting
```

2. **Create the environment**
```bash
conda env create -f environment.yml
conda activate taxi_demand_prediction
```

3. **Download data**
- Place raw trip data (Parquet) in `data/raw/`
- Place NYC weather data in `data/external/`
- Place `taxi+_zone_lookup.csv` in `data/external/`

4. **Run pipelines**
```bash
# Data ingestion
python src/data/data_ingestor.py

# Feature engineering
python src/features/feature_engineering.py

# Train baseline
python src/models/train_baseline_model.py

# Train advanced models
python src/models/train_advanced_models.py

# Run batch prediction
python models/batch-scoring_system/03_inference_pipeline.py

# Launch dashboard
streamlit run models/dashboard.py
```

---

## ğŸ§ª Evaluation Metrics

| Metric          | Description                                                   |
|-----------------|---------------------------------------------------------------|
| MAE             | Measures average error in predictions                         |
| RMSE            | Penalizes large errors more than MAE                          |
| Zone MAE        | Evaluates performance per Manhattan zone                      |
| MAE Drift       | Tracks model drift using online metrics vs. offline validation|

---

## ğŸ“Š Dashboard Preview

- **MAE over Time**: Monitor prediction accuracy during March 2019
- **Zone Heatmap**: Visualize actual/predicted demand across NYC zones
- **Prediction vs. Ground Truth**: Spot high-error scenarios
- **Drift Detection**: Compare online and offline MAE

---

## ğŸ“Œ Future Work

- Implement real-time ingestion (Kafka, APIs)
- Add zone-level metadata (population density, venues)
- Explore Deep Learning (RNNs, Transformers)
- Integrate anomaly detection for outlier demand

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENCE](./LICENCE.txt)) file for details.

---

## ğŸ™Œ Acknowledgments

- NYC TLC for public trip data
- National Weather Service API
- Taxi Zone Lookup data from NYC Open Data
