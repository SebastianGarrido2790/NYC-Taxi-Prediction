import pandas as pd
import numpy as np
from pathlib import Path
import logging
import matplotlib.pyplot as plt
import seaborn as sns
import mlflow

# Set up logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Project directory structure
BASE_DIR = Path(__file__).resolve().parent.parent.parent
ANALYSIS_DIR = BASE_DIR / "src" / "models" / "analysis"
BUSY_ZONES_DIR = ANALYSIS_DIR / "busy_zones"

# Ensure busy zones directory exists
BUSY_ZONES_DIR.mkdir(parents=True, exist_ok=True)

# Set up MLflow experiment (same as training)
EXPERIMENT_NAME = "NYC_Taxi_Demand_Advanced"
mlflow.set_experiment(EXPERIMENT_NAME)


def load_error_data():
    """Load the error analysis data generated by analyze_model.py."""
    logger.info("Loading error analysis data...")

    error_file = ANALYSIS_DIR / "xgboost_error_analysis.csv"
    if not error_file.exists():
        raise FileNotFoundError(f"Error analysis file not found at {error_file}")

    error_df = pd.read_csv(error_file)
    error_df["hourly_timestamp"] = pd.to_datetime(error_df["hourly_timestamp"])
    logger.info(f"Loaded error analysis data with {len(error_df)} rows.")

    return error_df


def identify_busy_zones(error_df, top_n=10):
    """Identify the top N zones with the highest average absolute error."""
    logger.info(f"Identifying top {top_n} zones with highest average absolute error...")

    error_by_zone = (
        error_df.groupby(["PULocationID", "zone"])["absolute_error"]
        .mean()
        .sort_values(ascending=False)
    )
    busy_zones = error_by_zone.head(top_n).reset_index()
    logger.info(f"Top {top_n} zones with highest average absolute error:")
    logger.info(busy_zones)

    # Save the list of busy zones
    busy_zones_file = BUSY_ZONES_DIR / "busy_zones.csv"
    busy_zones.to_csv(busy_zones_file, index=False)
    logger.info(f"Saved busy zones to {busy_zones_file}")
    mlflow.log_artifact(busy_zones_file)

    return busy_zones


def analyze_zone(zone_id, zone_name, zone_df):
    """Perform a detailed analysis for a specific zone."""
    logger.info(f"Analyzing zone {zone_id} ({zone_name}) with {len(zone_df)} rows...")

    # Create a directory for this zone's analysis
    zone_dir = BUSY_ZONES_DIR / f"zone_{zone_id}"
    zone_dir.mkdir(parents=True, exist_ok=True)

    # 1. Error Distribution (Histogram)
    plt.figure(figsize=(10, 6))
    sns.histplot(zone_df["absolute_error"], bins=50, kde=True)
    plt.title(f"Error Distribution for Zone {zone_id} ({zone_name})")
    plt.xlabel("Absolute Error")
    plt.ylabel("Frequency")
    plot_path = zone_dir / "error_distribution.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved error distribution plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # 2. Error by Hour of Day
    error_by_hour = zone_df.groupby("hour")["absolute_error"].mean()
    plt.figure(figsize=(10, 6))
    error_by_hour.plot()
    plt.title(f"Average Absolute Error by Hour of Day for Zone {zone_id} ({zone_name})")
    plt.xlabel("Hour of Day")
    plt.ylabel("Average Absolute Error")
    plt.grid(True)
    plot_path = zone_dir / "error_by_hour.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved error by hour plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # 3. Error by Day of Week
    error_by_day = zone_df.groupby("day_of_week")["absolute_error"].mean()
    plt.figure(figsize=(10, 6))
    error_by_day.plot()
    plt.title(f"Average Absolute Error by Day of Week for Zone {zone_id} ({zone_name})")
    plt.xlabel("Day of Week (0=Mon, 6=Sun)")
    plt.ylabel("Average Absolute Error")
    plt.grid(True)
    plot_path = zone_dir / "error_by_day.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved error by day plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # 4. Error by Rush Hour Status
    error_by_rush_hour = zone_df.groupby("is_rush_hour")["absolute_error"].mean()
    logger.info(
        f"Average absolute error by rush hour status for Zone {zone_id} ({zone_name}):"
    )
    logger.info(error_by_rush_hour)
    plt.figure(figsize=(6, 6))
    error_by_rush_hour.plot(kind="bar")
    plt.title(
        f"Average Absolute Error by Rush Hour Status for Zone {zone_id} ({zone_name})"
    )
    plt.xlabel("Is Rush Hour")
    plt.ylabel("Average Absolute Error")
    plt.xticks(ticks=[0, 1], labels=["No", "Yes"], rotation=0)
    plot_path = zone_dir / "error_by_rush_hour.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved error by rush hour plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # 5. Error by Weekend Status
    error_by_weekend = zone_df.groupby("is_weekend")["absolute_error"].mean()
    logger.info(
        f"Average absolute error by weekend status for Zone {zone_id} ({zone_name}):"
    )
    logger.info(error_by_weekend)
    plt.figure(figsize=(6, 6))
    error_by_weekend.plot(kind="bar")
    plt.title(
        f"Average Absolute Error by Weekend Status for Zone {zone_id} ({zone_name})"
    )
    plt.xlabel("Is Weekend")
    plt.ylabel("Average Absolute Error")
    plt.xticks(ticks=[0, 1], labels=["No", "Yes"], rotation=0)
    plot_path = zone_dir / "error_by_weekend.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved error by weekend plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # 6. Systematic Bias (Actual vs. Predicted)
    zone_df["error"] = (
        zone_df["predicted"] - zone_df["actual"]
    )  # Positive = overestimate, Negative = underestimate
    plt.figure(figsize=(10, 6))
    sns.histplot(zone_df["error"], bins=50, kde=True)
    plt.title(f"Prediction Error (Predicted - Actual) for Zone {zone_id} ({zone_name})")
    plt.xlabel("Prediction Error (Positive = Overestimate, Negative = Underestimate)")
    plt.ylabel("Frequency")
    plot_path = zone_dir / "systematic_bias.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved systematic bias plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # Log bias statistics
    mean_bias = zone_df["error"].mean()
    median_bias = zone_df["error"].median()
    logger.info(
        f"Mean prediction bias for Zone {zone_id} ({zone_name}): {mean_bias:.4f}"
    )
    logger.info(
        f"Median prediction bias for Zone {zone_id} ({zone_name}): {median_bias:.4f}"
    )
    mlflow.log_metric(f"zone_{zone_id}_mean_bias", mean_bias)
    mlflow.log_metric(f"zone_{zone_id}_median_bias", median_bias)

    # 7. Actual vs. Predicted Over Time (Sample 7 days for clarity)
    sample_df = zone_df.sort_values("hourly_timestamp").head(24 * 7)  # First 7 days
    plt.figure(figsize=(14, 6))
    plt.plot(
        sample_df["hourly_timestamp"], sample_df["actual"], label="Actual", alpha=0.7
    )
    plt.plot(
        sample_df["hourly_timestamp"],
        sample_df["predicted"],
        label="Predicted",
        alpha=0.7,
    )
    plt.title(f"Actual vs. Predicted Demand Over Time for Zone {zone_id} ({zone_name})")
    plt.xlabel("Timestamp")
    plt.ylabel("Ride Count")
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    plot_path = zone_dir / "actual_vs_predicted.png"
    plt.savefig(plot_path, bbox_inches="tight")
    plt.close()
    logger.info(f"Saved actual vs. predicted plot to {plot_path}")
    mlflow.log_artifact(plot_path)

    # Save the zone-specific error data
    zone_error_file = zone_dir / "error_data.csv"
    zone_df.to_csv(zone_error_file, index=False)
    logger.info(f"Saved zone error data to {zone_error_file}")
    mlflow.log_artifact(zone_error_file)


def main():
    logger.info("Starting busy zones analysis pipeline...")

    with mlflow.start_run(run_name="Busy_Zones_Analysis"):
        # Load the error analysis data
        error_df = load_error_data()

        # Identify the top high-error zones
        busy_zones = identify_busy_zones(error_df, top_n=10)

        # Analyze each busy zone
        for _, row in busy_zones.iterrows():
            zone_id = row["PULocationID"]
            zone_name = row["zone"]
            zone_df = error_df[error_df["PULocationID"] == zone_id]
            analyze_zone(zone_id, zone_name, zone_df)

    logger.info("Busy zones analysis pipeline completed.")


if __name__ == "__main__":
    main()
